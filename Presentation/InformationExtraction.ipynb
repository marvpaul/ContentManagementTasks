{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informationen aus einem Text extrahieren\n",
    "\n",
    "## Einteilung in Sätze und Wörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'an', 'example', '.', 'The', 'example', 'is', 'really', 'simple', '.']]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = \"This is an example. The example is really simple.\"\n",
    "tokenized = [nltk.word_tokenize(text)]\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkennung von Wortarten\n",
    "- DT -> Artikel\n",
    "\n",
    "- V* -> Verben in versch. Zeitformen, z.B. VBZ, VBN\n",
    "\n",
    "- NN -> Nomen\n",
    "\n",
    "- RB* -> Adverbien\n",
    "\n",
    "- JJ -> Adjektiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Print out all availiable part of speech tags\n",
    "print(nltk.help.upenn_tagset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('This', 'DT'), ('is', 'VBZ'), ('an', 'DT'), ('example', 'NN'), ('.', '.'), ('The', 'DT'), ('example', 'NN'), ('is', 'VBZ'), ('really', 'RB'), ('simple', 'JJ'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#Divide the example into part of speech tags\n",
    "speech_tags = [nltk.pos_tag(token) for token in tokenized]\n",
    "print(speech_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking / Einheiten gliedern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  (NP an/DT example/NN)\n",
      "  ./.\n",
      "  (NP The/DT example/NN)\n",
      "  is/VBZ\n",
      "  really/RB\n",
      "  simple/JJ\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "#Define a grammar for our chunks\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "#Define chunk parser which includes the defined grammar\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "#Parse\n",
    "result = cp.parse(speech_tags[0])\n",
    "\n",
    "#Print and draw result as a tree\n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CHUNK each/DT medical/JJ)\n",
      "(CHUNK this/DT disturbing/JJ)\n",
      "(CHUNK another/DT major/JJ)\n",
      "(CHUNK each/DT additional/JJ)\n",
      "(CHUNK this/DT historic/JJ)\n",
      "(CHUNK this/DT historic/JJ)\n",
      "(CHUNK this/DT two-year/JJ)\n",
      "(CHUNK another/DT splendid/JJ)\n",
      "(CHUNK another/DT all-out/JJ)\n",
      "(CHUNK another/DT 5-run/JJ)\n",
      "(CHUNK this/DT early/JJ)\n",
      "(CHUNK That/DT darlin'/JJ)\n",
      "(CHUNK This/DT mad/JJ)\n",
      "(CHUNK that/DT crazy/JJ)\n",
      "(CHUNK this/DT vast/JJ)\n",
      "(CHUNK that/DT bleak/JJ)\n",
      "(CHUNK that/DT magic/JJ)\n",
      "(CHUNK this/DT fine/JJ)\n",
      "(CHUNK this/DT little/JJ)\n",
      "(CHUNK this/DT regrettable/JJ)\n",
      "(CHUNK that/DT historic/JJ)\n",
      "(CHUNK This/DT year-to-year/JJ)\n",
      "(CHUNK this/DT tremendous/JJ)\n",
      "(CHUNK That/DT 60-day/JJ)\n",
      "(CHUNK this/DT cultural/JJ)\n",
      "(CHUNK that/DT Mexican/JJ)\n",
      "(CHUNK another/DT real/JJ)\n",
      "(CHUNK that/DT old/JJ)\n",
      "(CHUNK this/DT three-hour/JJ)\n",
      "(CHUNK This/DT excellent/JJ)\n",
      "(CHUNK this/DT broad/JJ)\n",
      "(CHUNK that/DT oft-repeated/JJ)\n",
      "(CHUNK this/DT untrammeled/JJ)\n",
      "(CHUNK that/DT congressional/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT remarkable/JJ)\n",
      "(CHUNK that/DT final/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT ultimate/JJ)\n",
      "(CHUNK that/DT august/JJ)\n",
      "(CHUNK that/DT rare/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT Braddock-against-the-Indians/JJ)\n",
      "(CHUNK this/DT basic/JJ)\n",
      "(CHUNK this/DT feeble/JJ)\n",
      "(CHUNK this/DT sensitive/JJ)\n",
      "(CHUNK this/DT local/JJ)\n",
      "(CHUNK this/DT unilateral/JJ)\n",
      "(CHUNK Another/DT optimistic/JJ)\n",
      "(CHUNK this/DT budget-altering/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT open/JJ)\n",
      "(CHUNK this/DT majestic/JJ)\n",
      "(CHUNK that/DT slow/JJ)\n",
      "(CHUNK that/DT thin/JJ)\n",
      "(CHUNK that/DT big/JJ)\n",
      "(CHUNK that/DT big/JJ)\n",
      "(CHUNK each/DT autistic/JJ)\n",
      "(CHUNK This/DT immature/JJ)\n",
      "(CHUNK this/DT grassroots-fueled/JJ)\n",
      "(CHUNK this/DT huge/JJ)\n",
      "(CHUNK this/DT British/JJ)\n",
      "(CHUNK another/DT congratulatory/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK another/DT intelligent/JJ)\n",
      "(CHUNK this/DT acrobatic/JJ)\n",
      "(CHUNK this/DT precarious/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT nuclear/JJ)\n",
      "(CHUNK this/DT nuclear/JJ)\n",
      "(CHUNK this/DT mad/JJ)\n",
      "(CHUNK that/DT little/JJ)\n",
      "(CHUNK this/DT small/JJ)\n",
      "(CHUNK this/DT small/JJ)\n",
      "(CHUNK each/DT successive/JJ)\n",
      "(CHUNK another/DT remarkable/JJ)\n",
      "(CHUNK another/DT religious/JJ)\n",
      "(CHUNK That/DT Aristotelean-Thomistic/JJ)\n",
      "(CHUNK This/DT prime/JJ)\n",
      "(CHUNK this/DT uni-directional/JJ)\n",
      "(CHUNK that/DT famous/JJ)\n",
      "(CHUNK that/DT interminable/JJ)\n",
      "(CHUNK this/DT governmental/JJ)\n",
      "(CHUNK this/DT able/JJ)\n",
      "(CHUNK this/DT late/JJ)\n",
      "(CHUNK this/DT amazing/JJ)\n",
      "(CHUNK this/DT critical/JJ)\n",
      "(CHUNK another/DT big/JJ)\n",
      "(CHUNK that/DT preposterous/JJ)\n",
      "(CHUNK this/DT mutual/JJ)\n",
      "(CHUNK this/DT poignant/JJ)\n",
      "(CHUNK this/DT deep-eyed/JJ)\n",
      "(CHUNK this/DT musical/JJ)\n",
      "(CHUNK Each/DT high/JJ)\n",
      "(CHUNK This/DT big/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK that/DT pale/JJ)\n",
      "(CHUNK that/DT short/JJ)\n",
      "(CHUNK that/DT adorable/JJ)\n",
      "(CHUNK this/DT brief/JJ)\n",
      "(CHUNK this/DT unhappy/JJ)\n",
      "(CHUNK This/DT fascinating/JJ)\n",
      "(CHUNK that/DT truant/JJ)\n",
      "(CHUNK this/DT unenviable/JJ)\n",
      "(CHUNK this/DT religious/JJ)\n",
      "(CHUNK this/DT urgent/JJ)\n",
      "(CHUNK this/DT challenging/JJ)\n",
      "(CHUNK this/DT mystic/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT healthy/JJ)\n",
      "(CHUNK This/DT slim/JJ)\n",
      "(CHUNK that/DT subtle/JJ)\n",
      "(CHUNK another/DT brilliant/JJ)\n",
      "(CHUNK that/DT pedimented/JJ)\n",
      "(CHUNK this/DT aural/JJ)\n",
      "(CHUNK that/DT inaugural/JJ)\n",
      "(CHUNK that/DT genial/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK This/DT French/JJ)\n",
      "(CHUNK that/DT broad/JJ)\n",
      "(CHUNK this/DT dismal/JJ)\n",
      "(CHUNK this/DT invincible/JJ)\n",
      "(CHUNK that/DT true/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT true/JJ)\n",
      "(CHUNK this/DT important/JJ)\n",
      "(CHUNK this/DT long/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT present-day/JJ)\n",
      "(CHUNK this/DT Catholic/JJ)\n",
      "(CHUNK each/DT historical/JJ)\n",
      "(CHUNK this/DT near/JJ)\n",
      "(CHUNK that/DT liberal/JJ)\n",
      "(CHUNK that/DT empty/JJ)\n",
      "(CHUNK that/DT spiritual/JJ)\n",
      "(CHUNK that/DT great/JJ)\n",
      "(CHUNK this/DT hard-won/JJ)\n",
      "(CHUNK This/DT whole/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT momentous/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK Another/DT major/JJ)\n",
      "(CHUNK this/DT dynamic/JJ)\n",
      "(CHUNK this/DT constitutional/JJ)\n",
      "(CHUNK this/DT evil/JJ)\n",
      "(CHUNK this/DT true/JJ)\n",
      "(CHUNK This/DT narrow/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK that/DT metallic/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT clear/JJ)\n",
      "(CHUNK this/DT atomic/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT timeless/JJ)\n",
      "(CHUNK this/DT different/JJ)\n",
      "(CHUNK this/DT esoteric/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT astounding/JJ)\n",
      "(CHUNK This/DT happy/JJ)\n",
      "(CHUNK this/DT vigorous/JJ)\n",
      "(CHUNK that/DT steel-edged/JJ)\n",
      "(CHUNK that/DT dramatic/JJ)\n",
      "(CHUNK this/DT fine/JJ)\n",
      "(CHUNK this/DT fine/JJ)\n",
      "(CHUNK That/DT cold/JJ)\n",
      "(CHUNK that/DT late/JJ)\n",
      "(CHUNK each/DT separate/JJ)\n",
      "(CHUNK This/DT delightful/JJ)\n",
      "(CHUNK that/DT delightful/JJ)\n",
      "(CHUNK that/DT post-attack/JJ)\n",
      "(CHUNK this/DT bargain-priced/JJ)\n",
      "(CHUNK another/DT home-bred/JJ)\n",
      "(CHUNK This/DT thoughtful/JJ)\n",
      "(CHUNK this/DT unfair/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT free/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK another/DT good/JJ)\n",
      "(CHUNK another/DT promising/JJ)\n",
      "(CHUNK another/DT fine-looking/JJ)\n",
      "(CHUNK this/DT little/JJ)\n",
      "(CHUNK this/DT 11-shot/JJ)\n",
      "(CHUNK this/DT original/JJ)\n",
      "(CHUNK this/DT special/JJ)\n",
      "(CHUNK Another/DT scenic/JJ)\n",
      "(CHUNK another/DT unique/JJ)\n",
      "(CHUNK another/DT small/JJ)\n",
      "(CHUNK each/DT skinless/JJ)\n",
      "(CHUNK This/DT two-part/JJ)\n",
      "(CHUNK this/DT historic/JJ)\n",
      "(CHUNK this/DT world-wide/JJ)\n",
      "(CHUNK this/DT happy/JJ)\n",
      "(CHUNK this/DT historical/JJ)\n",
      "(CHUNK this/DT English/JJ)\n",
      "(CHUNK that/DT over-all/JJ)\n",
      "(CHUNK this/DT early/JJ)\n",
      "(CHUNK this/DT linear/JJ)\n",
      "(CHUNK that/DT final/JJ)\n",
      "(CHUNK this/DT essential/JJ)\n",
      "(CHUNK this/DT novel/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK This/DT original/JJ)\n",
      "(CHUNK this/DT novel/JJ)\n",
      "(CHUNK this/DT onward-driving/JJ)\n",
      "(CHUNK this/DT quixotic/JJ)\n",
      "(CHUNK this/DT promising/JJ)\n",
      "(CHUNK this/DT whole/JJ)\n",
      "(CHUNK this/DT fast-growing/JJ)\n",
      "(CHUNK each/DT major/JJ)\n",
      "(CHUNK this/DT exciting/JJ)\n",
      "(CHUNK This/DT anomalous/JJ)\n",
      "(CHUNK this/DT 70-mile-long/JJ)\n",
      "(CHUNK this/DT classical/JJ)\n",
      "(CHUNK This/DT whole/JJ)\n",
      "(CHUNK that/DT old/JJ)\n",
      "(CHUNK another/DT new/JJ)\n",
      "(CHUNK this/DT complex/JJ)\n",
      "(CHUNK that/DT wanting-to-be-alone/JJ)\n",
      "(CHUNK that/DT elemental/JJ)\n",
      "(CHUNK this/DT additional/JJ)\n",
      "(CHUNK This/DT basic/JJ)\n",
      "(CHUNK this/DT seven-word/JJ)\n",
      "(CHUNK this/DT high-powered/JJ)\n",
      "(CHUNK another/DT emotional/JJ)\n",
      "(CHUNK another/DT emotional/JJ)\n",
      "(CHUNK that/DT early/JJ)\n",
      "(CHUNK that/DT old/JJ)\n",
      "(CHUNK that/DT filthy/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK that/DT weird/JJ)\n",
      "(CHUNK that/DT weird/JJ)\n",
      "(CHUNK that/DT realistic/JJ)\n",
      "(CHUNK that/DT identical/JJ)\n",
      "(CHUNK that/DT hard/JJ)\n",
      "(CHUNK that/DT lovely/JJ)\n",
      "(CHUNK this/DT procreative/JJ)\n",
      "(CHUNK this/DT inner/JJ)\n",
      "(CHUNK this/DT anatomical/JJ)\n",
      "(CHUNK another/DT quaint/JJ)\n",
      "(CHUNK this/DT big/JJ)\n",
      "(CHUNK this/DT modern/JJ)\n",
      "(CHUNK each/DT front/JJ)\n",
      "(CHUNK This/DT serious/JJ)\n",
      "(CHUNK this/DT beyond-normal/JJ)\n",
      "(CHUNK each/DT little/JJ)\n",
      "(CHUNK this/DT small/JJ)\n",
      "(CHUNK this/DT historical/JJ)\n",
      "(CHUNK this/DT divisive/JJ)\n",
      "(CHUNK That/DT tumultuous/JJ)\n",
      "(CHUNK This/DT epic/JJ)\n",
      "(CHUNK that/DT unfortunate/JJ)\n",
      "(CHUNK this/DT arduous/JJ)\n",
      "(CHUNK that/DT orney/JJ)\n",
      "(CHUNK another/DT propagandistic/JJ)\n",
      "(CHUNK this/DT ignorant/JJ)\n",
      "(CHUNK that/DT fabled/JJ)\n",
      "(CHUNK this/DT diversionary/JJ)\n",
      "(CHUNK This/DT ignorant/JJ)\n",
      "(CHUNK that/DT vast/JJ)\n",
      "(CHUNK that/DT Communist/JJ)\n",
      "(CHUNK this/DT little/JJ)\n",
      "(CHUNK this/DT large/JJ)\n",
      "(CHUNK that/DT special/JJ)\n",
      "(CHUNK Another/DT frequent/JJ)\n",
      "(CHUNK Another/DT common/JJ)\n",
      "(CHUNK Each/DT human/JJ)\n",
      "(CHUNK this/DT southern/JJ)\n",
      "(CHUNK This/DT carefree/JJ)\n",
      "(CHUNK this/DT long/JJ)\n",
      "(CHUNK another/DT vicious/JJ)\n",
      "(CHUNK This/DT nondrying/JJ)\n",
      "(CHUNK another/DT nondrying/JJ)\n",
      "(CHUNK this/DT carefree/JJ)\n",
      "(CHUNK that/DT thick/JJ)\n",
      "(CHUNK this/DT strange/JJ)\n",
      "(CHUNK This/DT new/JJ)\n",
      "(CHUNK that/DT particular/JJ)\n",
      "(CHUNK this/DT young/JJ)\n",
      "(CHUNK this/DT powerful/JJ)\n",
      "(CHUNK this/DT attractive/JJ)\n",
      "(CHUNK that/DT extra/JJ)\n",
      "(CHUNK This/DT circular/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK This/DT perpetual/JJ)\n",
      "(CHUNK this/DT political/JJ)\n",
      "(CHUNK this/DT extensive/JJ)\n",
      "(CHUNK this/DT dark/JJ)\n",
      "(CHUNK another/DT busy/JJ)\n",
      "(CHUNK another/DT specific/JJ)\n",
      "(CHUNK this/DT fantastic/JJ)\n",
      "(CHUNK this/DT rich/JJ)\n",
      "(CHUNK this/DT anonymous/JJ)\n",
      "(CHUNK this/DT true/JJ)\n",
      "(CHUNK this/DT special/JJ)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CHUNK This/DT new/JJ)\n",
      "(CHUNK that/DT senior/JJ)\n",
      "(CHUNK this/DT strong/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK This/DT bold/JJ)\n",
      "(CHUNK this/DT crass/JJ)\n",
      "(CHUNK this/DT phenomenal/JJ)\n",
      "(CHUNK this/DT vital/JJ)\n",
      "(CHUNK this/DT fine/JJ)\n",
      "(CHUNK this/DT life-death/JJ)\n",
      "(CHUNK this/DT brief/JJ)\n",
      "(CHUNK this/DT sexual/JJ)\n",
      "(CHUNK this/DT disaffiliated/JJ)\n",
      "(CHUNK This/DT strange/JJ)\n",
      "(CHUNK this/DT little/JJ)\n",
      "(CHUNK this/DT unknown/JJ)\n",
      "(CHUNK this/DT terrible/JJ)\n",
      "(CHUNK that/DT great/JJ)\n",
      "(CHUNK that/DT fair/JJ)\n",
      "(CHUNK this/DT final/JJ)\n",
      "(CHUNK That/DT little/JJ)\n",
      "(CHUNK That/DT little/JJ)\n",
      "(CHUNK This/DT restless/JJ)\n",
      "(CHUNK that/DT desperate/JJ)\n",
      "(CHUNK this/DT unpromising/JJ)\n",
      "(CHUNK this/DT curious/JJ)\n",
      "(CHUNK this/DT idyllic/JJ)\n",
      "(CHUNK this/DT fatal/JJ)\n",
      "(CHUNK this/DT fatal/JJ)\n",
      "(CHUNK This/DT organizational/JJ)\n",
      "(CHUNK this/DT early/JJ)\n",
      "(CHUNK that/DT utopian/JJ)\n",
      "(CHUNK This/DT favorable/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT human/JJ)\n",
      "(CHUNK this/DT natural/JJ)\n",
      "(CHUNK this/DT questionable/JJ)\n",
      "(CHUNK this/DT personal/JJ)\n",
      "(CHUNK that/DT psychological/JJ)\n",
      "(CHUNK another/DT bad/JJ)\n",
      "(CHUNK each/DT planetary/JJ)\n",
      "(CHUNK that/DT popular/JJ)\n",
      "(CHUNK this/DT strange/JJ)\n",
      "(CHUNK another/DT destructive/JJ)\n",
      "(CHUNK that/DT particular/JJ)\n",
      "(CHUNK that/DT self-consuming/JJ)\n",
      "(CHUNK this/DT precocious/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK that/DT subtle/JJ)\n",
      "(CHUNK this/DT titanic/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT destructive/JJ)\n",
      "(CHUNK this/DT 195-page/JJ)\n",
      "(CHUNK this/DT simple/JJ)\n",
      "(CHUNK this/DT strange/JJ)\n",
      "(CHUNK that/DT young/JJ)\n",
      "(CHUNK this/DT final/JJ)\n",
      "(CHUNK that/DT supreme/JJ)\n",
      "(CHUNK That/DT unused/JJ)\n",
      "(CHUNK that/DT odd/JJ)\n",
      "(CHUNK that/DT young/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT spontaneous/JJ)\n",
      "(CHUNK this/DT independent/JJ)\n",
      "(CHUNK this/DT modest/JJ)\n",
      "(CHUNK that/DT spontaneous/JJ)\n",
      "(CHUNK that/DT personal/JJ)\n",
      "(CHUNK each/DT sizable/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT frank/JJ)\n",
      "(CHUNK that/DT noble/JJ)\n",
      "(CHUNK this/DT careful/JJ)\n",
      "(CHUNK that/DT magnificent/JJ)\n",
      "(CHUNK Another/DT beautiful/JJ)\n",
      "(CHUNK Another/DT classic/JJ)\n",
      "(CHUNK that/DT imcomparable/JJ)\n",
      "(CHUNK This/DT agreeable/JJ)\n",
      "(CHUNK this/DT perfidious/JJ)\n",
      "(CHUNK This/DT warm/JJ)\n",
      "(CHUNK this/DT political/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK that/DT alert/JJ)\n",
      "(CHUNK this/DT long/JJ)\n",
      "(CHUNK This/DT intellectual/JJ)\n",
      "(CHUNK this/DT subtle/JJ)\n",
      "(CHUNK that/DT classical/JJ)\n",
      "(CHUNK this/DT early/JJ)\n",
      "(CHUNK that/DT prevalent/JJ)\n",
      "(CHUNK that/DT small/JJ)\n",
      "(CHUNK another/DT telling/JJ)\n",
      "(CHUNK another/DT able/JJ)\n",
      "(CHUNK that/DT apt/JJ)\n",
      "(CHUNK This/DT lofty/JJ)\n",
      "(CHUNK This/DT huge/JJ)\n",
      "(CHUNK this/DT technological/JJ)\n",
      "(CHUNK this/DT picturesque/JJ)\n",
      "(CHUNK This/DT enviable/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT tremendous/JJ)\n",
      "(CHUNK that/DT ordinary/JJ)\n",
      "(CHUNK another/DT indispensable/JJ)\n",
      "(CHUNK this/DT basic/JJ)\n",
      "(CHUNK this/DT dogmatic/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK this/DT human/JJ)\n",
      "(CHUNK that/DT lovable/JJ)\n",
      "(CHUNK that/DT wonderful/JJ)\n",
      "(CHUNK This/DT whole/JJ)\n",
      "(CHUNK that/DT long/JJ)\n",
      "(CHUNK that/DT horrible/JJ)\n",
      "(CHUNK this/DT baffling/JJ)\n",
      "(CHUNK this/DT Latin/JJ)\n",
      "(CHUNK that/DT famous/JJ)\n",
      "(CHUNK that/DT short/JJ)\n",
      "(CHUNK this/DT cause-and-effect/JJ)\n",
      "(CHUNK that/DT utopian/JJ)\n",
      "(CHUNK that/DT unblemished/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK This/DT magnificent/JJ)\n",
      "(CHUNK This/DT central/JJ)\n",
      "(CHUNK This/DT new/JJ)\n",
      "(CHUNK that/DT human/JJ)\n",
      "(CHUNK Another/DT powerful/JJ)\n",
      "(CHUNK this/DT national/JJ)\n",
      "(CHUNK This/DT angry/JJ)\n",
      "(CHUNK that/DT awful/JJ)\n",
      "(CHUNK that/DT slight/JJ)\n",
      "(CHUNK this/DT forward/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT humane/JJ)\n",
      "(CHUNK this/DT parliamentary/JJ)\n",
      "(CHUNK this/DT humble/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK that/DT notable/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK This/DT financial/JJ)\n",
      "(CHUNK that/DT particular/JJ)\n",
      "(CHUNK another/DT common/JJ)\n",
      "(CHUNK this/DT outstanding/JJ)\n",
      "(CHUNK this/DT unusual/JJ)\n",
      "(CHUNK this/DT great/JJ)\n",
      "(CHUNK each/DT regular/JJ)\n",
      "(CHUNK this/DT joint/JJ)\n",
      "(CHUNK this/DT joint/JJ)\n",
      "(CHUNK this/DT joint/JJ)\n",
      "(CHUNK Another/DT recent/JJ)\n",
      "(CHUNK another/DT important/JJ)\n",
      "(CHUNK each/DT national/JJ)\n",
      "(CHUNK this/DT important/JJ)\n",
      "(CHUNK this/DT Russian/JJ)\n",
      "(CHUNK this/DT Russian/JJ)\n",
      "(CHUNK this/DT voluminous/JJ)\n",
      "(CHUNK each/DT annual/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK This/DT temporary/JJ)\n",
      "(CHUNK this/DT urgent/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK This/DT broad/JJ)\n",
      "(CHUNK this/DT automatic/JJ)\n",
      "(CHUNK this/DT automatic/JJ)\n",
      "(CHUNK this/DT automatic/JJ)\n",
      "(CHUNK that/DT individual/JJ)\n",
      "(CHUNK another/DT basic/JJ)\n",
      "(CHUNK this/DT basic/JJ)\n",
      "(CHUNK that/DT famous/JJ)\n",
      "(CHUNK this/DT necessary/JJ)\n",
      "(CHUNK This/DT new/JJ)\n",
      "(CHUNK another/DT substantial/JJ)\n",
      "(CHUNK another/DT good/JJ)\n",
      "(CHUNK another/DT good/JJ)\n",
      "(CHUNK This/DT sporadic/JJ)\n",
      "(CHUNK This/DT small/JJ)\n",
      "(CHUNK this/DT hot/JJ)\n",
      "(CHUNK this/DT negative/JJ)\n",
      "(CHUNK This/DT negative/JJ)\n",
      "(CHUNK This/DT large/JJ)\n",
      "(CHUNK Another/DT important/JJ)\n",
      "(CHUNK Each/DT male/JJ)\n",
      "(CHUNK each/DT individual/JJ)\n",
      "(CHUNK that/DT famous/JJ)\n",
      "(CHUNK this/DT gruesome/JJ)\n",
      "(CHUNK this/DT crucial/JJ)\n",
      "(CHUNK this/DT close/JJ)\n",
      "(CHUNK This/DT pleural/JJ)\n",
      "(CHUNK this/DT bronchial/JJ)\n",
      "(CHUNK this/DT alveolar/JJ)\n",
      "(CHUNK this/DT general/JJ)\n",
      "(CHUNK this/DT abnormal/JJ)\n",
      "(CHUNK This/DT specific/JJ)\n",
      "(CHUNK this/DT brief/JJ)\n",
      "(CHUNK this/DT central/JJ)\n",
      "(CHUNK this/DT reciprocal/JJ)\n",
      "(CHUNK this/DT differential/JJ)\n",
      "(CHUNK each/DT possible/JJ)\n",
      "(CHUNK this/DT random/JJ)\n",
      "(CHUNK Each/DT binomial/JJ)\n",
      "(CHUNK each/DT binomial/JJ)\n",
      "(CHUNK Another/DT great/JJ)\n",
      "(CHUNK this/DT relationship-building/JJ)\n",
      "(CHUNK each/DT important/JJ)\n",
      "(CHUNK another/DT prominent/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK this/DT supportive/JJ)\n",
      "(CHUNK this/DT social/JJ)\n",
      "(CHUNK this/DT social/JJ)\n",
      "(CHUNK another/DT important/JJ)\n",
      "(CHUNK This/DT experimental/JJ)\n",
      "(CHUNK this/DT special/JJ)\n",
      "(CHUNK this/DT democratic/JJ)\n",
      "(CHUNK this/DT additional/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK this/DT unique/JJ)\n",
      "(CHUNK this/DT particular/JJ)\n",
      "(CHUNK another/DT schizophrenic/JJ)\n",
      "(CHUNK each/DT distinct/JJ)\n",
      "(CHUNK each/DT phonologic/JJ)\n",
      "(CHUNK this/DT abstract/JJ)\n",
      "(CHUNK this/DT average/JJ)\n",
      "(CHUNK this/DT basic/JJ)\n",
      "(CHUNK this/DT Hegelian/JJ)\n",
      "(CHUNK this/DT true/JJ)\n",
      "(CHUNK this/DT true/JJ)\n",
      "(CHUNK this/DT crucial/JJ)\n",
      "(CHUNK this/DT crucial/JJ)\n",
      "(CHUNK another/DT excess/JJ)\n",
      "(CHUNK this/DT comparative/JJ)\n",
      "(CHUNK this/DT economic/JJ)\n",
      "(CHUNK This/DT past/JJ)\n",
      "(CHUNK Each/DT new/JJ)\n",
      "(CHUNK this/DT American/JJ)\n",
      "(CHUNK another/DT social/JJ)\n",
      "(CHUNK another/DT upward-mobile/JJ)\n",
      "(CHUNK Another/DT public/JJ)\n",
      "(CHUNK this/DT threefold/JJ)\n",
      "(CHUNK each/DT social/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT neutral/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT fundamental/JJ)\n",
      "(CHUNK that/DT solid/JJ)\n",
      "(CHUNK this/DT marvelous/JJ)\n",
      "(CHUNK another/DT low/JJ)\n",
      "(CHUNK that/DT dreary/JJ)\n",
      "(CHUNK this/DT Stoic-patristic/JJ)\n",
      "(CHUNK this/DT fearful/JJ)\n",
      "(CHUNK this/DT undepicted/JJ)\n",
      "(CHUNK that/DT vigorous/JJ)\n",
      "(CHUNK this/DT giddy/JJ)\n",
      "(CHUNK this/DT ethical/JJ)\n",
      "(CHUNK that/DT cold/JJ)\n",
      "(CHUNK this/DT lifelike/JJ)\n",
      "(CHUNK another/DT sudden/JJ)\n",
      "(CHUNK this/DT fluent/JJ)\n",
      "(CHUNK that/DT universal/JJ)\n",
      "(CHUNK another/DT moral/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK This/DT unusual/JJ)\n",
      "(CHUNK each/DT compatible/JJ)\n",
      "(CHUNK another/DT natural/JJ)\n",
      "(CHUNK this/DT general/JJ)\n",
      "(CHUNK this/DT important/JJ)\n",
      "(CHUNK that/DT due/JJ)\n",
      "(CHUNK that/DT due/JJ)\n",
      "(CHUNK this/DT experimental/JJ)\n",
      "(CHUNK each/DT new/JJ)\n",
      "(CHUNK this/DT short/JJ)\n",
      "(CHUNK that/DT stone-gray/JJ)\n",
      "(CHUNK this/DT dainty/JJ)\n",
      "(CHUNK This/DT young/JJ)\n",
      "(CHUNK this/DT religious/JJ)\n",
      "(CHUNK That/DT goddamn/JJ)\n",
      "(CHUNK this/DT Parisian/JJ)\n",
      "(CHUNK that/DT brief/JJ)\n",
      "(CHUNK that/DT painful/JJ)\n",
      "(CHUNK that/DT misty/JJ)\n",
      "(CHUNK this/DT heavy/JJ)\n",
      "(CHUNK that/DT vile/JJ)\n",
      "(CHUNK that/DT marvelous/JJ)\n",
      "(CHUNK that/DT lush/JJ)\n",
      "(CHUNK that/DT long/JJ)\n",
      "(CHUNK this/DT full-grown/JJ)\n",
      "(CHUNK this/DT old/JJ)\n",
      "(CHUNK another/DT black/JJ)\n",
      "(CHUNK this/DT big/JJ)\n",
      "(CHUNK this/DT big/JJ)\n",
      "(CHUNK this/DT handsome/JJ)\n",
      "(CHUNK this/DT apocalyptic/JJ)\n",
      "(CHUNK this/DT long/JJ)\n",
      "(CHUNK this/DT black/JJ)\n",
      "(CHUNK that/DT sweet/JJ)\n",
      "(CHUNK that/DT sickish/JJ)\n",
      "(CHUNK that/DT filthy/JJ)\n",
      "(CHUNK that/DT smooth/JJ)\n",
      "(CHUNK that/DT smooth/JJ)\n",
      "(CHUNK this/DT guileless/JJ)\n",
      "(CHUNK that/DT brief/JJ)\n",
      "(CHUNK this/DT little/JJ)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CHUNK that/DT dear/JJ)\n",
      "(CHUNK this/DT lonely/JJ)\n",
      "(CHUNK Each/DT successive/JJ)\n",
      "(CHUNK that/DT short/JJ)\n",
      "(CHUNK that/DT dry/JJ)\n",
      "(CHUNK this/DT broken-nosed/JJ)\n",
      "(CHUNK this/DT half-grown/JJ)\n",
      "(CHUNK another/DT important/JJ)\n",
      "(CHUNK this/DT big/JJ)\n",
      "(CHUNK that/DT fool/JJ)\n",
      "(CHUNK that/DT dull/JJ)\n",
      "(CHUNK another/DT sidelong/JJ)\n",
      "(CHUNK that/DT threatening/JJ)\n",
      "(CHUNK another/DT dim/JJ)\n",
      "(CHUNK this/DT underground/JJ)\n",
      "(CHUNK another/DT hot/JJ)\n",
      "(CHUNK that/DT Yankee/JJ)\n",
      "(CHUNK another/DT curious/JJ)\n",
      "(CHUNK this/DT early/JJ)\n",
      "(CHUNK this/DT startling/JJ)\n",
      "(CHUNK this/DT unaccountable/JJ)\n",
      "(CHUNK that/DT ridiculous/JJ)\n",
      "(CHUNK that/DT childish/JJ)\n",
      "(CHUNK that/DT crazy/JJ)\n",
      "(CHUNK that/DT young/JJ)\n",
      "(CHUNK that/DT old/JJ)\n",
      "(CHUNK that/DT simple/JJ)\n",
      "(CHUNK that/DT tall/JJ)\n",
      "(CHUNK That/DT damn/JJ)\n",
      "(CHUNK this/DT past/JJ)\n",
      "(CHUNK this/DT alien/JJ)\n",
      "(CHUNK this/DT big/JJ)\n",
      "(CHUNK this/DT typical/JJ)\n",
      "(CHUNK that/DT particular/JJ)\n",
      "(CHUNK that/DT theatrical/JJ)\n",
      "(CHUNK that/DT curious/JJ)\n",
      "(CHUNK this/DT sad/JJ)\n",
      "(CHUNK that/DT damn/JJ)\n",
      "(CHUNK that/DT lousy/JJ)\n",
      "(CHUNK each/DT tiny/JJ)\n",
      "(CHUNK that/DT stupid/JJ)\n",
      "(CHUNK that/DT enormous/JJ)\n",
      "(CHUNK this/DT happy/JJ)\n",
      "(CHUNK that/DT fat/JJ)\n",
      "(CHUNK this/DT glorious/JJ)\n",
      "(CHUNK That/DT cold/JJ)\n",
      "(CHUNK This/DT fiery/JJ)\n",
      "(CHUNK This/DT old/JJ)\n",
      "(CHUNK this/DT nice/JJ)\n",
      "(CHUNK this/DT pompous/JJ)\n",
      "(CHUNK this/DT dapper/JJ)\n",
      "(CHUNK another/DT long/JJ)\n",
      "(CHUNK this/DT unwholesome/JJ)\n",
      "(CHUNK this/DT demoniac/JJ)\n",
      "(CHUNK this/DT evil/JJ)\n",
      "(CHUNK that/DT stupid/JJ)\n",
      "(CHUNK another/DT gut-flattening/JJ)\n",
      "(CHUNK that/DT small/JJ)\n",
      "(CHUNK That/DT long/JJ)\n",
      "(CHUNK This/DT dirty/JJ)\n",
      "(CHUNK this/DT whole/JJ)\n",
      "(CHUNK this/DT far/JJ)\n",
      "(CHUNK this/DT muddy/JJ)\n",
      "(CHUNK this/DT goddamn/JJ)\n",
      "(CHUNK this/DT unfamiliar/JJ)\n",
      "(CHUNK this/DT small/JJ)\n",
      "(CHUNK another/DT city-wide/JJ)\n",
      "(CHUNK that/DT slow/JJ)\n",
      "(CHUNK this/DT meek/JJ)\n",
      "(CHUNK That/DT long/JJ)\n",
      "(CHUNK that/DT great/JJ)\n",
      "(CHUNK this/DT pathless/JJ)\n",
      "(CHUNK this/DT interminable/JJ)\n",
      "(CHUNK that/DT barefoot/JJ)\n",
      "(CHUNK that/DT black/JJ)\n",
      "(CHUNK that/DT filthy/JJ)\n",
      "(CHUNK this/DT strange/JJ)\n",
      "(CHUNK that/DT right/JJ)\n",
      "(CHUNK this/DT vast/JJ)\n",
      "(CHUNK this/DT hot/JJ)\n",
      "(CHUNK This/DT young/JJ)\n",
      "(CHUNK Another/DT young/JJ)\n",
      "(CHUNK That/DT poor/JJ)\n",
      "(CHUNK that/DT sneaky/JJ)\n",
      "(CHUNK that/DT simple/JJ)\n",
      "(CHUNK this/DT handsome/JJ)\n",
      "(CHUNK that/DT pretty/JJ)\n",
      "(CHUNK this/DT new/JJ)\n",
      "(CHUNK this/DT sentimental/JJ)\n",
      "(CHUNK this/DT old/JJ)\n",
      "(CHUNK this/DT impossible/JJ)\n",
      "(CHUNK this/DT little/JJ)\n",
      "(CHUNK This/DT tragic/JJ)\n",
      "(CHUNK this/DT big/JJ)\n",
      "(CHUNK that/DT warm/JJ)\n",
      "(CHUNK that/DT ghastly/JJ)\n",
      "(CHUNK this/DT harsh/JJ)\n",
      "(CHUNK that/DT final/JJ)\n",
      "(CHUNK that/DT old/JJ)\n",
      "(CHUNK that/DT double-married/JJ)\n",
      "(CHUNK that/DT effete/JJ)\n",
      "(CHUNK this/DT freakish/JJ)\n",
      "(CHUNK this/DT ridiculous/JJ)\n",
      "(CHUNK that/DT big/JJ)\n",
      "(CHUNK that/DT long/JJ)\n",
      "(CHUNK That/DT stupid/JJ)\n",
      "(CHUNK this/DT late/JJ)\n",
      "(CHUNK that/DT long/JJ)\n",
      "(CHUNK this/DT sad/JJ)\n",
      "(CHUNK that/DT new/JJ)\n",
      "(CHUNK that/DT big/JJ)\n",
      "(CHUNK another/DT well-dressed/JJ)\n",
      "(CHUNK that/DT frightful/JJ)\n",
      "(CHUNK this/DT magnificent/JJ)\n",
      "(CHUNK this/DT fine/JJ)\n",
      "(CHUNK this/DT miserable/JJ)\n",
      "(CHUNK that/DT long/JJ)\n",
      "(CHUNK That/DT pale/JJ)\n",
      "(CHUNK That/DT pale/JJ)\n",
      "(CHUNK that/DT peaked/JJ)\n",
      "(CHUNK that/DT transparent/JJ)\n",
      "(CHUNK that/DT solemn/JJ)\n",
      "(CHUNK that/DT radiant/JJ)\n",
      "(CHUNK that/DT dry/JJ)\n",
      "(CHUNK that/DT good/JJ)\n",
      "(CHUNK that/DT brutal/JJ)\n",
      "(CHUNK that/DT frenetic/JJ)\n",
      "(CHUNK that/DT clear/JJ)\n",
      "(CHUNK that/DT good/JJ)\n",
      "(CHUNK this/DT risky/JJ)\n",
      "(CHUNK this/DT suburban/JJ)\n",
      "(CHUNK this/DT unparalleled/JJ)\n",
      "(CHUNK this/DT turbulent/JJ)\n",
      "(CHUNK that/DT great/JJ)\n",
      "(CHUNK that/DT pretty/JJ)\n",
      "(CHUNK This/DT baffling/JJ)\n",
      "(CHUNK that/DT definite/JJ)\n",
      "(CHUNK that/DT handy/JJ)\n",
      "(CHUNK that/DT funny/JJ)\n",
      "(CHUNK that/DT silly/JJ)\n",
      "(CHUNK this/DT small/JJ)\n",
      "(CHUNK this/DT nice/JJ)\n",
      "(CHUNK This/DT happy/JJ)\n",
      "(CHUNK this/DT titanic/JJ)\n",
      "(CHUNK that/DT nebulous/JJ)\n",
      "(CHUNK this/DT theatrical/JJ)\n",
      "(CHUNK this/DT unpretentious/JJ)\n",
      "(CHUNK This/DT brief/JJ)\n",
      "(CHUNK this/DT revolutionary/JJ)\n",
      "(CHUNK this/DT young/JJ)\n"
     ]
    }
   ],
   "source": [
    "#define some other chunks, in this case just searching for determiner plus adjective\n",
    "cp = nltk.RegexpParser('CHUNK: {<DT> <JJ>}')\n",
    "brown = nltk.corpus.brown\n",
    "for sentence in brown.tagged_sents():\n",
    "    tree = cp.parse(sentence)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'CHUNK': print(subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinking - das Gegenteil von Chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  (NP an/DT example/NN)\n",
      "  ./.\n",
      "  (NP The/DT example/NN)\n",
      "  is/VBZ\n",
      "  really/RB\n",
      "  simple/JJ\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "#Define a grammar where we exclude some part of speech tags from beeing a NP \n",
    "grammar = r\"\"\"\n",
    "            NP: \n",
    "                {<.*>+} \n",
    "                }<DT> <VBZ>{\n",
    "                }<VBZ> <RB> <JJ>{\n",
    "                }<.>{\n",
    "        \"\"\"\n",
    "\n",
    "#Define chunk parser which includes the defined grammar\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "#Parse\n",
    "result = cp.parse(speech_tags[0])\n",
    "\n",
    "#Print and draw result as a tree\n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entwickeln von Chunkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Over/IN\n",
      "  (NP a/DT cup/NN)\n",
      "  of/IN\n",
      "  (NP coffee/NN)\n",
      "  ,/,\n",
      "  (NP Mr./NNP Stone/NNP)\n",
      "  told/VBD\n",
      "  (NP his/PRP$ story/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "#Trainings dataset\n",
    "print(conll2000.chunked_sents('train.txt', chunk_types=['NP'])[99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keine Chunking-Regeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  43.4%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(\"\")\n",
    "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
    "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einfache Grammatik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  59.7%%\n",
      "    Precision:     45.3%%\n",
      "    Recall:        24.2%%\n",
      "    F-Measure:     31.6%%\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(\"NP: {<DT>?<JJ>*<NN>}\")\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram Tagger\n",
    "--> Statistische Analyse von Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  92.9%%\n",
      "    Precision:     79.9%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     83.2%%\n"
     ]
    }
   ],
   "source": [
    "class UnigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_data = []\n",
    "        for sentence in train_sents:\n",
    "            #Reformatting \n",
    "            reformatted_sentence = nltk.chunk.tree2conlltags(sentence)\n",
    "\n",
    "            #Extract the (tag, chunk) out of (tag, word, chunk) triple\n",
    "            tag_chunk = [(t, c) for w,t,c in reformatted_sentence]\n",
    "            train_data.append(tag_chunk)\n",
    "\n",
    "        #Overgive the data to UnigramTagger\n",
    "        self.tagger = nltk.UnigramTagger(train_data)\n",
    "    def parse(self, sentence):\n",
    "        #Extract part of speech tags\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        \n",
    "        #Tag the sentence by recognizing part of speech patterns using the trained tagger\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        \n",
    "        #Get the chunk tags \n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        \n",
    "        #Combine the sentence and the determined chunk tags (IOB format)\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]\n",
    "        \n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "\n",
    "#Train the unigram chunker\n",
    "unigram_chunker = UnigramChunker(train_sents)\n",
    "\n",
    "print(unigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (GPE U.S./NNP)\n",
      "  is/VBZ\n",
      "  one/CD\n",
      "  of/IN\n",
      "  the/DT\n",
      "  few/JJ\n",
      "  industrialized/VBN\n",
      "  nations/NNS\n",
      "  that/WDT\n",
      "  *T*-7/-NONE-\n",
      "  does/VBZ\n",
      "  n't/RB\n",
      "  have/VB\n",
      "  a/DT\n",
      "  higher/JJR\n",
      "  standard/NN\n",
      "  of/IN\n",
      "  regulation/NN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  smooth/JJ\n",
      "  ,/,\n",
      "  needle-like/JJ\n",
      "  fibers/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  crocidolite/NN\n",
      "  that/WDT\n",
      "  *T*-1/-NONE-\n",
      "  are/VBP\n",
      "  classified/VBN\n",
      "  *-5/-NONE-\n",
      "  as/IN\n",
      "  amphobiles/NNS\n",
      "  ,/,\n",
      "  according/VBG\n",
      "  to/TO\n",
      "  (PERSON Brooke/NNP T./NNP Mossman/NNP)\n",
      "  ,/,\n",
      "  a/DT\n",
      "  professor/NN\n",
      "  of/IN\n",
      "  pathlogy/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION University/NNP)\n",
      "  of/IN\n",
      "  (PERSON Vermont/NNP College/NNP)\n",
      "  of/IN\n",
      "  (GPE Medicine/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sent = nltk.corpus.treebank.tagged_sents()[22]\n",
    "print(nltk.ne_chunk(sent, binary=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Beziehungen erkennen \n",
    "Beziehungen in Texten erkennen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n",
      "[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n",
      "[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n",
      "[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n",
      "[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n",
      "[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n",
      "[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n",
      "[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n",
      "[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n",
      "[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n",
      "[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n",
      "[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n",
      "[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#Defining a regular expr.\n",
    "#TODO: What does this regex mean?\n",
    "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "#Go throught all docs in NYT from 1998 03 15 \n",
    "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
    "    #Get each relation between ORG and LOC which follows the pattern IN\n",
    "    #[ORG] ... in [LOC]\n",
    "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, corpus='ieer', pattern = IN):\n",
    "        print(nltk.sem.rtuple(rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
